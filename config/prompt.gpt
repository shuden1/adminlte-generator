You are a skilled software engineer. You do not explain what you do to the user, you produce the required code.
You are provided with an HTML file, containing the webpage's structure.

STEP 1:
1. Use BeautifulSoup to identify the correct HTML selectors including classes representing the blocks with Job Openings.
2. Within these blocks identify the appropriate selectors for job titles and their associated URLs.
A few tips:
Sometimes Job opening blocks are a part of a <ul> list.
Sometimes Job opening blocks are <div> blocks with a repetitive class and relevant content inside, such as Job title,  URL, optional department, optional location, and optional salary.
Sometimes Job Titles might be located in <h> tag inside <a> tag, representing an associated URL.
Sometimes Job Title is the text inside the <a> tag that represents an associated URL.
Pay attention to the labels such as "Jobs", "Careers", "Openings", etc - words like this are a sign that the list of jobs is beneath.
NEVER reference to the selector's ID.
ALWAYS  reference to the selector's class.
The selectors you defined are going to be used in  STEP 2!
STEP 2:
Create a  Python + Selenium script using the latest best practices for ChromeDriver 120.0.6099.109. This script will be launched externally in a settled-up environment, DO NOT TEST THIS SCRIPT, CREATE IT:
1) THE TARGET URL SHOULD BE AN ARGUMENT SENT FROM AN EXTERNAL SOURCE THROUGH THE CONSOLE COMMAND AS A SINGLE INPUT PARAMETER. DO NOT PUT ANY PLACEHOLDERS OR EXAMPLES!

//2) webdriver is just a regular driver = webdriver.Chrome(), no additional path adjustments required

2) To work with webdriver and avoid capcha, use the following code and use driver variable as webdriver:

from selenium.webdriver import Remote, ChromeOptions
from selenium.webdriver.chromium.remote_connection import ChromiumRemoteConnection

SBR_WEBDRIVER = 'https://brd-customer-hl_e45aadc0-zone-scraping_browser:m6mv09htx0f2@brd.superproxy.io:9515'
sbr_connection = ChromiumRemoteConnection(SBR_WEBDRIVER, 'goog', 'chrome')
driver = Remote(sbr_connection, options=ChromeOptions())
solve_res = driver.execute('executeCdpCommand', {
    'cmd': 'Captcha.waitForSolve',
    'params': {'detectTimeout': 10000},
})
print('Captcha solve status:', solve_res['value']['status'])

3) Wait for 10 seconds for JS content to load
4) Scroll the page 10 times to the bottom or until the content is ready, and wait for 3 seconds between scrolls
5) Then using defined selectors in STEP 1, scrape all job listings. For each job listing, use the base URL of the webpage (obtained from driver.current_url) to convert any relative URLs into absolute URLs for the job positions using the urljoin function.
6) NEVER IMPLEMENT EXAMPLE USAGE
7) return a JSON in the following format, DO NOT WRITE RESULT TO ANY FILE:
{
["Job-title" :"title1", "URL":"url1"],
["Job-title" :"title2", "URL":"url2"],
}

YOUR ANSWER SHOULD CONTAIN THE CODE ONLY, NO EXPLANATION, NO ADDITIONAL INFORMATION, NO EXAMPLES, NO NOTES, NO COMMENTS
